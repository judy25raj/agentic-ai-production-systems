# ðŸ§  Agentic AI â€” Reliability Command Center (ELK Observability)

ðŸ **STATUS: PROJECT COMPLETE**  
This project is finalized and maintained for portfolio and demonstration purposes.

This project demonstrates a production-style AI observability platform that monitors agent behavior in real time using the Elastic Stack (Elasticsearch + Kibana).

It brings SRE-style monitoring to LLM and agentic AI systems by tracking:

- â±ï¸ Latency  
- â­ Response quality (Judge score)  
- ðŸš¨ Hallucination risk  
- ðŸ’¸ Token usage  
- ðŸ”— Trace correlation  

---

## ðŸ” What the System Does

Emits structured telemetry from an AI agent and a Judge Agent into Elasticsearch, then visualizes reliability signals in Kibana dashboards.

---

## ðŸ” Pipeline Flow

AI Agent â†’ Judge Agent â†’ Telemetry JSON â†’ Elasticsearch â†’ Kibana Dashboards

---

## ðŸ“Š Captured Signals

| Field | Meaning |
|------|---------|
| latency_ms | Performance |
| judge.score | Response quality |
| judge.hallucination | Risk flag |
| tokens | Cost proxy |
| trace.id | Correlation ID |

---

## ðŸ§° Tech Stack

- Python 3.10+
- Elasticsearch 8.x
- Kibana (Lens Dashboards)
- Docker + Docker Compose
- requests (HTTP telemetry)

---

## âš¡ Quick Start

```bash
docker compose up -d
pip install requests
python demo_ai.py
```

Open Kibana: http://localhost:5601

Create Data View:

- **Name:** llm-events-demo  
- **Time field:** @timestamp  

---

## ðŸ“ˆ Dashboards

- **Avg AI Latency (ms)** â€“ Monitors response time  
- **Avg AI Quality** â€“ Tracks reliability  
- **Hallucinations Detected** â€“ Flags unsafe responses  

---

## ðŸ“‚ Repository Layout

```
ai-reliability-command-center/
â”œâ”€â”€ demo_ai.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ screenshots/
â””â”€â”€ README.md
```

---

## ðŸ”Ž Useful Filters (KQL)

```kql
judge.hallucination : true
latency_ms > 1500
judge.score < 0.75
```

---

## ðŸ“ Notes

- This project does not use external web search  
- Telemetry is structured JSON for production-style observability  
- Designed for portfolio use: clean, repeatable, no private data  
- Mirrors real-world AI reliability monitoring patterns  
