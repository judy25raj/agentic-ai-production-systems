ðŸ§  Agentic AI â€” Reliability Command Center (ELK Observability)

ðŸ STATUS: PROJECT COMPLETE
This project is finalized and maintained for portfolio and demonstration purposes.

This project demonstrates a production-style AI observability platform that monitors agent behavior in real time using the Elastic Stack (Elasticsearch + Kibana).

It brings SRE-style monitoring to LLM and agentic AI systems by tracking:

Latency

Response quality (Judge score)

Hallucination risk

Token usage

Trace correlation

What the System Does

Emits structured telemetry from an AI agent and judge agent into Elasticsearch, then visualizes reliability signals in Kibana.

Pipeline Flow

AI Agent â†’ Judge Agent â†’ Telemetry JSON â†’ Elasticsearch â†’ Kibana Dashboards

Captured Signals

latency_ms â†’ performance

judge.score â†’ quality

judge.hallucination â†’ risk

tokens â†’ cost proxy

trace.id â†’ correlation

Tech Stack

Python 3.10+

Elasticsearch 8.x

Kibana (Lens Dashboards)

Docker + Docker Compose

requests (HTTP telemetry)

Quick Start
1) Start ELK
docker compose up -d

2) Install dependencies
pip install requests

3) Generate observability events
python demo_ai.py


Run multiple times to populate the dashboards.

4) Open Kibana
http://localhost:5601


Create a data view:

Name: llm-events-demo

Time field: @timestamp

Dashboards
Panel	Description
Avg AI Latency (ms)	Monitors response time
Avg AI Quality (Judge Score)	Tracks reliability
Hallucinations Detected	Flags unsafe responses
Repository Layout
ai-reliability-command-center/
â”œâ”€â”€ demo_ai.py                # Agent + Judge + telemetry
â”œâ”€â”€ docker-compose.yml       # Elasticsearch + Kibana
â”œâ”€â”€ screenshots/             # Dashboard images
â””â”€â”€ README.md

Useful Filters (KQL)

Show hallucinations:

judge.hallucination : true


Slow responses:

latency_ms > 1500


Low quality:

judge.score < 0.75

Notes

This project does not use external web search

Telemetry is structured JSON for production-style observability

Designed for portfolio use: clean, repeatable, no private data

Mirrors real-world AI reliability monitoring patterns
